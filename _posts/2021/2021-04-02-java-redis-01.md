---
layout:     post
title:      "可不敢吹自己会Redis-01"
subtitle:   "Redis基础、数据结构、key过期策略、内存淘汰机制、持久化机制、redis事务、缓存穿透、缓存击穿、缓存雪崩、并发竞争key、双写一致性"
date:       2021-04-02
author:     "ThreeJin"
header-mask: 0.5
catalog: true
header-img: "https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-bk.png"
tags:
    - Java
    - Redis

---
> 资料来源于网络上各位前辈总结以及实践过程中的积累

### 前言
留下的坑，终究还是要来填的。之前一直计划着要把在项目里面使用Redis的一些踩坑记录一下，今天终于有时间来沉淀了。话不多说，直接开搞。
### redis 简介
全称，Remote Dictionary Server，简单来说 redis 就是一个数据库，不过与传统数据库不同的是 redis 的数据是存在内存中的，所以存写速度非常快，因此 redis 被广泛应用于缓存方向。另外，redis 也经常用来做分布式锁（这个目前在项目中还没有玩儿过）。redis 提供了多种数据类型来支持不同的业务场景。除此之外，redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案
##### 为啥要用Redis？
- 高性能和分担压力  
那必须是高性能，操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可。其次就是在高并发的时候可以分担数据库压力。  
- 有些时候，也有地方在用来作为分布式锁，但是如果仅仅是分布式锁这些，完全可以用中间件ZooKeeper等代替  
- 为什么要用 redis 而不用 map/guava 做缓存?  
缓存分为本地缓存和分布式缓存。以 Java 为例，使用map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束。所以，在多实例的情况下，每个实例都是各自保存一份缓存，缓存不一致，或者说要做到缓存一致的话耗费的资源比较大。  
redis 或 memcached 可以做到分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂

#####  redis和memcached区别  
- memcache仅支持简单的文本或二进制类型；redis支持多种数据类型  
- memecached是将数据全部存在内存之中；redis还支持数据的持久化  
- memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；redis则原生支持 cluster 模式的  
- memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型  

![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-01-01.jpg)  

### 数据结构
谈到Redis的数据结构，其实是指value的的类型，在这之前，先说一下redis的key  
##### key的结构
redis的key 值是字符串储存的，这意味着可以用任何文本作为key值，从形如”foo”的简单字符串到一个JPEG文件的内容都可以  
**空字符串也是有效key值**  
键值不需要太长，首先消耗内存过多，其次键值计算成本较高（查询耗时长）  
key的几个命令：set、del、get、mget、exists、**incr**、**decr**、expire、type等，注意`OBJECT ENCODING key `可以查看底层的数据结构  
redis每创建一个key，都会为这个键储存一些附加的管理信息（比如这个键的类型，这个键最后一次被访问的时间等等），因此redis的key相对于值来说更珍贵  
reids数据库中的key越多，redis数据库服务器在储存附加管理信息方面耗费的内存就越多，在获取key对应的value值时cpu的开销也会更多  
Redis 中所有的 key 都存储在一个很大的字典中，这个字典的结构和 Java 中的 HashMap 一样，是一维数组 + 二维链表结构，第一维数组的大小总是 2^n(n>=0)，扩容一次数组大小空间加倍，也就是 n++  
##### String

- 常用命令: `set,get,decr,incr,mget` 等  
- value其实不仅可以是String，也可以是数字  
- 场景  
    - 计数器：许多系统都会使用Redis作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存  
    - 集群的时候共享session  
- **底层存储结构**：**<font color=red>简单动态字符串SDS（simple dynamic string）</font>**  
    - 规定字符串的长度不超过512M字节  
    - 相对于C语言字符串，SDS具有常数复杂度获取字符串长度，杜绝了缓存区的溢出，减少了修改字符串长度时所需的内存重分配次数，以及二进制安全能存储各种类型的文件，并且还兼容部分C函数  
- **底层存储方式**   
    ![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-01-02.jpg)   
    <center>SDS的具体分类</center>  
    ![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-01-03.jpg)   
    <center>两种差异</center>  
    其他字符中，embstr（对象头和SDS对象连续存储在一起）和raw（两个对象头在内存地址上一般是不连续的），其中44的标准其实就跟完整的 embstr 对象需要的内存大小有关   
- **扩容方式**  
当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M

##### Hash

- 常用命令: hget,hset,hgetall 等  
- Hash 是一个 string 类型的 field 和 value 的映射表，有点像`Map<String,Map<field,value>>`，hash 特别适合用于存储对象，后续操作的时候，可以直接仅仅修改这个对象中的某个字段的值   
- 一个hash中最多包含`2^32-1`键值对  
- redis的key的过期功能只能对键操作，而**Hash结构不能单独对某一个filed设置过期功能**  
- 场景：缓存实体类，注意，这里一般是指没有嵌套其他对象的实体类  
- **底层存储结构**：**<font color=red>压缩列表（元素对象较少时）或者字典</font>**
    - 当元素较多时结构为字典表，其中包括有两个哈希表，一个平时使用，另一个仅在进行rehash时使用  
    - redis解决hash冲突的方法是链地址法，被分配到同一个索引上的多个键值对会连接成一个单向链表  
- **扩容**  
当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍，但是如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容  
- **缩容**  
当 hash 表因为元素的逐渐删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。缩容的条件是元素个数低于数组长度的 10%。缩容不会考虑 Redis 是否正在做 bgsave  
- **渐进式rehash**  
也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作  
所以Redis采用渐进式 rehash，这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的。  

##### List

- 常用命令: lpush,rpush,lpop,rpop,lrange 等  
- list 就是链表，它的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销    
- 可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询  
- 最多包含2^32-1元素  
- 场景  
    - 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西，最主要的是还可以实现分页  
    - 当成队列来使用：Redis的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据  
    
- **底层存储结构**：**<font color=red>早期版本中是压缩列表+双向链表，后来变更为快表quicklist</font>**  
    - 是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值，而且可以快速定位元素（有点数组的感觉）  
    - 压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存  
    - `quicklist`=`ziplist`+`linkedlist`，将linkedlist按段拆分，每一段使用ziplist来紧凑存储，多个ziplist之间使用双向指针串联，单个ziplist长度8k字节，超出这个字节数，新起一个ziplist  
    ![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-01-04.jpg)   

##### set

- 常用命令: sadd,spop,smembers,sunion 等  
- set 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的  
- **底层存储结构**：**<font color=red>IntSet数组（元素对象较少时，可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素）或字典</font>**  

##### zset

- 常用命令: zadd,zrange,zrem,zcard 等  
- 和set相比，zset增加了一个权重参数score，使得集合中的元素能够按score进行有序排列  
- **底层存储结构**：**<font color=red>压缩列表（元素较少的时候）或跳表</font>**  

![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-01-05.jpg)   
    - 由很多层结构组成，每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的节点  
    - 上一层的元素是当前层的元素的子集  
    - **链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点**  
    - 最底层的链表包含了所有的元素  
    - 元素越多，查找效率越高，空间换时间  

##### 特-Geospatial
Redis 在 3.2 推出 Geo 类型，该功能可以推算出地理位置信息，两地之间的距离。一般会下载城市数据，直接通过java程序一次性导入，有效的经度从-180度到180度，有效的纬度从-85.05112878度到85.05112878度  
- 添加地理位置：`getadd`  
- 获得当前定位：一定是一个坐标值，`getpos`  
- 获得两个坐标之间的直线距离：`GEODIST`  
- 以给定的经纬度为中心，返回键包含的位置元素当中，与中心的距离不超过给定最大距离的所有位置元素：`GEORADIUS`  
- **GEO 底层的实现原理其实就是 Zset**

##### 特-Hyperloglog
Redis 2.8.9 版本更新了 hyperloglog 数据结构，是基于基数统计的算法  
- 优点是占用内存小，并且是固定的。存储 `2^64` 个不同元素的基数，只需要 12 KB 的空间。但是也可能有 0.81% 的错误率  
- 场景：常用于统计网站的 UV。传统的方式是使用 set 保存用户的ID，然后统计 set 中元素的数量作为判断标准。但是这种方式保存了大量的用户 ID，ID 一般比较长，占空间，还很麻烦。我们的目的是计数，不是保存数据，所以这样做有弊端。但是如果使用 hyperloglog 就比较合适了  
- 命令：  
    - `pfadd` 和 `pfcount`，这两个常用，前者用于创建元素，后者用于统计元素个数  
    - `pfmerge`：用于将多个 `pf` 计数值累加在一起形成一个新的 `pf` 值，取并集
    
```txt
127.0.0.1:6379> pfadd mykey a b c d e f g h i j	# 创建第一组元素
(integer) 1
127.0.0.1:6379> PFCOUNT mykey # 统计 mykey 基数
(integer) 10
127.0.0.1:6379> PFADD mykey2 i j z x c v b n m  # 创建第二组元素
(integer) 1
127.0.0.1:6379> PFCOUNT mykey2 # 统计 mykey2 基数
(integer) 9
127.0.0.1:6379> PFMERGE mykey3 mykey mykey2 # 合并两组 mykey mykey2 => mykey3
OK
127.0.0.1:6379> PFCOUNT mykey3
(integer) 15
```

##### 特-Bitmap

- 数据结构：都是二进制位进行记录,只有0 和 1 两个状态  
- 应用场景：统计用户信息活跃与不活跃, 登录与未登录,打卡与未打卡情况等, 两个状态的应用场景都可以使用该类型

### key过期了怎么办？
这里就涉及到redis的过期策略：**<font color=red>定期删除+惰性删除</font>**  
##### 定期+随机抽取删除
redis默认是每隔 100ms 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载  
##### 惰性删除
定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。也就是定期删除没有涉及到的key在过期之后，如果再被检索到的话再执行删除  
### 内存淘汰机制
作为一个内存数据库，redis在内存空间不足的时候，为了保证命中率，就会选择一定的数据淘汰策略。这样一个场景：MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据？这就涉及到redis 提供的数据淘汰策略：  
- **volatile-lru**：从已设置过期时间的数据集（server.db\[i\].expires）中挑选**最近最少使用**的数据淘汰  
- **volatile-ttl**：从已设置过期时间的数据集（server.db\[i\].expires）中挑选**将要过期**的数据淘汰  
- **volatile-random**：从已设置过期时间的数据集（server.db\[i\].expires）中**任意选择**数据淘汰  
- **allkeys-lru**：**当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）**  
- **allkeys-random**：从数据集（server.db\[i\].dict）中任意选择数据淘汰  
- **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，**新写入操作会报错**  

### 持久化机制
Redis支持持久化，而且支持两种不同的持久化操作：一种持久化方式叫快照（snapshotting，RDB）,另一种方式是只追加文件（append-only file,AOF）  
##### RDB
Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本，是内存数据的二进制序列化形式，在存储上非常紧凑。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用  
快照持久化是Redis默认采用的持久化方式，在`redis.conf配置文件`中默认有此下配置：  
```txt
save 900 1  #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 300 10  #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 60 10000  #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

这时候就有个很有意思的事情了，为了不阻塞线上的业务，Redis需要一边持久化一边响应客户端请求。持久化的同时，内存数据结构还在改变，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它给删掉了，还没持久化完呢，这怎么办呢？  
**<font color=red>Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化</font>**  
- 多进程  
    - Redis 在持久化时会调用 `glibc 的函数fork`产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求  
    - 子进程和父进程共享内存里面的代码段和数据段。这是 Linux 操作系统的机制，为了节约内存资源，所以会尽可能让它们共享起来。在进程分离的一瞬间，内存的增长几乎没有明显变化  
    - 子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程必须持续服务客户端请求，然后对内存数据结构进行不间断的修改  
- **Copy On Write**  
主要是利用该机制来对数据段页面进行分离操作。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的 2 倍大小。另外一个 Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4K，一个 Redis 实例里面一般都会有成千上万的页面  
**子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了**

##### AOF
- **是什么？**  
    - AOF 日志存储的是对内存进行修改的Redis 服务器的顺序指令序列  
    - Redis 会在收到客户端修改指令后，进行参数校验进行逻辑处理后（类似于SQL引擎检查SQL一样），如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是先执行指令才将日志存盘。这点不同于leveldb、hbase等存储引擎，它们都是先存储日志再做逻辑处理  
- **为什么？**
假设 AOF 日志记录了自 Redis 实例创建以来所有的修改性指令序列，那么就可以通过对一个空的 Redis 实例顺序执行所有的指令，也就是「重放」，来恢复 Redis 当前实例的内存数据结构的状态  
- **在哪儿？**  
开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过`dir参数`设置的，默认的文件名是`appendonly.aof`  
- **有什么问题？**  
Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身，参考混合持久化  
- **怎么使用？**  
    - 与RDB持久化相比，AOF持久化的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF持久化，可以通过`appendonly yes`参数开启  
    - 三种不同的 AOF 持久化方式  

```txt
appendfsync always     #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
appendfsync no      #让操作系统决定何时进行同步
```

#####  混合持久化
Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）  
- **是什么？**  
将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小  
- **为什么？**
在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升  
- **特点**  
如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差

### redis 事务
Redis 通过 `MULTI、EXEC、WATCH、discard` 等命令来实现事务功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求
##### 大致过程
所有的指令在 `exec` 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 `exec` 指令，才开执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。因为 Redis 的单线程特性，它不用担心自己在执行队列的时候被其它指令打搅
##### 原子性
Redis 的事务根本不能算「原子性」，而仅仅是满足了事务的「隔离性」，或者说是隔离性中的串行化，即当前执行的事务有着不被其它事务打断的权利
##### 乐观锁
Redis 提供了这种 `watch` 的机制，它就是一种乐观锁。`watch` 会在事务开始之前盯住 1 个或多个关键变量，当事务执行时，也就是服务器收到了`exec`指令要顺序执行缓存的事务队列时，Redis 会检查关键变量自 `watch` 之后，是否被修改了 (包括当前事务所在的客户端)。如果关键变量被人动过了，`exec` 指令就会返回 null 回复告知客户端事务执行失败，客户端知道了事务执行是失败后，通常都会抛出一个 `WatchError` 这种错误，不过也有些语言 (jedis) 不会抛出异常，而是通过在 `exec` 方法里返回一个 null，这样客户端需要检查一下返回结果是否为 null 来确定事务是否执行失败
### 缓存雪崩怎么办？
缓存在同一时间大面积的失效，此后的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉
##### Redis服务端
- 尽量保证整个 redis 集群的高可用性(主从架构+Sentinel或者Redis Cluster)，发现机器宕机尽快补上  
- 选择合适的内存淘汰策略  
- 在原有的key失效时间基础上增加一个随机值，比如1-5分钟随机，避免同一时间大面积key过期  

##### 加锁或者队列
这种方法仅适用于低并发的时候。在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待  
业界比较常用的做法，是使用`mutex key`策略。简单地来说，就是在缓存失效的时候（判断拿出来的值为空）不立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的`SETNX`或者Memcache的`ADD`）去set一个mutex key，当操作返回成功时，意味着此时没有其他线程在持有该锁，可以进行load db的操作并回设缓存；否则，就重试整个get缓存的方法
##### 缓存reload机制
针对使用率高的缓存，就不用设置超时或超时设置足够大，然后按业务需求时间间隔定期从DB重新加载/刷新缓存数据，这缓存就不会出现失效情况，也不出现雪崩现象  
或者，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期
##### 使用缓存标记
给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存  
- 缓存标记  
记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际key的缓存    
- 缓存数据  
它的过期时间比缓存标记的时间延长1倍，例：标记缓存时间30分钟，数据缓存设置为60分钟。 这样，当缓存标记key过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存
  
```java
//伪代码
public object GetProductListNew() {
    int cacheTime = 30;
    String cacheKey = "product_list";
    //缓存标记
    String cacheSign = cacheKey + "_sign";

    String sign = CacheHelper.Get(cacheSign);
    //获取缓存值
    String cacheValue = CacheHelper.Get(cacheKey);
    if (sign != null) {
        return cacheValue; //未过期，直接返回
    } else {
        CacheHelper.Add(cacheSign, "1", cacheTime);
        ThreadPool.QueueUserWorkItem((arg) -> {
      //这里一般是 sql查询数据
            cacheValue = GetProductListFromDB(); 
          //日期设缓存时间的2倍，用于脏读
          CacheHelper.Add(cacheKey, cacheValue, cacheTime * 2);                 
        });
        return cacheValue;
    }
} 
```

##### 双缓存策略
A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期
##### 持久化恢复  
利用 redis 持久化机制保存的数据尽快恢复缓存  
### 缓存穿透
##### 什么是缓存穿透？
故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉  
##### 解决办法
- 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。**Redis 官方提供的布隆过滤器到了 Redis 4.0 提供了插件功能之后才正式登场**  
- 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟  

### 缓存击穿
##### 什么是缓存击穿？
和缓存雪崩有点类似，只不过这里是指特定的一些热点key在某一时刻同时失效，导致这时的热点请求全部转发到DB
##### 解决办法
- **布隆过滤器**  
将所有可能存在的数据哈希到一个足够大的bitmap中，如果请求一个不存在的数据时会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力  
- 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟  

### 并发竞争Key
所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和期望的顺序不同，这样也就导致了结果的不同  
##### 分布式锁

![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-01-06.jpg)  

- zookeeper 和 redis 都可以实现分布式锁  
- 如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能  
- 基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁  
- 如果还对操作顺序有要求  
    - 可以结合分**布式锁+时间戳**的方式：在数据写入数据库的时候，需要保存一个时间戳，比如`key 1 {valueA 3:00}`，在抢到锁后发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作  
    - 把set操作引入队列，变成串行执行

##### redis的事务控制
通过redis的事务机制来控制并发竞争key
### 数据双写一致性
因为只要用缓存，就可能会涉及到缓存与数据库双存双写，只要是双写，就一定要考虑数据一致性的问题，首先，如果真的并发量不够的话，其实是可以允许缓存和数据库存在稍微的不一致  
所以，这里有一个概念：最终一致性和强一致性，如果是强一致性的，其实都不建议搞缓存  
同时，针对读的话，基本上都是采用的**先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存**，处理方式的不同在于到底是先操作缓存还是先操作数据库  
到底是删除缓存还是更新缓存，这个我觉得应该结合实际的业务来进行分析，删除虽然是lazy的策略，但是如果更新很繁琐，其实还不如删除  
##### 读写串行化
读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况，但是就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求  
##### 先更DB再删cache（这是目前主流，即Cache Aside Pattern）
为什么不先删cache，再更DB？因为这种依然可能会有不一致的情况：**先操作缓存，在写数据库成功之前，如果有读请求发生，可能导致旧数据入缓存，引发数据不一致**，所以CAP原则应运而生  
- 读的时候  
**先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存**，同时返回响应  
- 更新的时候  
**先更新数据库，然后再删除缓存**，注意这种依然可能会有不一致的情况：**缓存刚好失效，请求A查询数据库，得一个旧值。请求B将新值写入数据库然后先删除缓存，随后请求A才将查到的旧值写入了缓存**。这只是理论上的分析，其实这种情况只有当写的执行时间作比读的执行时间还要快的时候，才会出现，在实际中是很难出现的，如果真的有，依然有解决方案  
- <font color=red>Redis设置key的过期时间，保证cache会定期过期</font>  
- **<font color=red>延时异步双删策略</font>**  
    - 延时  
    顾名思义，第一次删除cache后，延时一段时间，比如1s，然后再判断一次cahe有没有被写入新的数据，如果有则再次删除cache。这么做，可以将延时的这1s内所造成的缓存脏数据，再次删除。那么，问题就在于这个1s是怎么确定的？那就要根据具体的业务来分析了。一般来说是根据项目的读数据业务逻辑的耗时（如果没有mySQL读写分离，那么就正常，有的话就加上主从数据同步的时间），写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可  
    - 异步  
    将第二次删除作为异步删除，避免了每次写操作的等待  

##### 延时双删失败了咋办？
即使有了升级版的延时双删，也有可能出现缓存删除失败的时候，这个时候怎么办呢？  
首先，还是那句话，一切都要具体业务具体分析，如果对一致性要求不是很高，那么直接在程序中另起一个线程，每隔一段时间去重试即可  
如果，有很高的一致性要求，那么可以尝试一下队列的方式：  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-01-07.jpg)  
说明：(1)更新数据库数据(2)数据库会将操作信息写入binlog日志当中(3)订阅程序提取出所需要的数据以及key(4)另起一段非业务代码，获得该信息(5)尝试删除缓存操作，发现删除失败(6)将这些信息发送至消息队列(7)重新从消息队列中获得该数据，重试操作  
**上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能**

### 其他坑
##### ip绑定问题
- Connection refused: connect  
把Redis的配置文件redis.conf里的 bind localhost（或者bind 127.0.0.1，表明只有该主机才能访问）注释掉，或者修改为：bind ip表明，只能通过ip访问  
##### 等待redis的连接
在生产环境中一定要配置GenericObjectPoolConfig中的 `maxIdle、maxTotal、minIdle`.因为里面默认值太低了，如果生产环境中流量比较大的话，就会出现等待redis的连接的情况。**maxIdle，maxTotal 最佳实践为 maxIdle = maxTotal**

为了更好的使用redis 连接池，建议采用 `JedisPoolConfig`来替代`GenericObjectPoolConfig`。JedisPoolConfig里面有一些默认的参数
