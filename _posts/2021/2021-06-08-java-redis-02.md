---
layout:     post
title:      "可不敢吹自己会Redis-02"
subtitle:   "为什么Redis这么快？Redis的分布式锁、Redission、Zookeeper的分布式锁"
update-date:       2021-06-08
author:     "ThreeJin"
header-mask: 0.5
catalog: true
header-img: "https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-bk.png"
tags:
    - Java
    - Redis
    - Zookeeper
    - 分布式

---
> 资料来源于网络上各位前辈（闪客sun、悟空聊架构）

### 前言
都知道Redis即使是单线程也能在高并发的场景下表现不俗，也都知道底层用的是I/O多路复用，但是真正知道什么是I/O多路复用吗？为什么会逐渐发展处这样的技术呢？这些都是需要自己去认真思考的，知其然也要知其所以然。
### 为什么Redis这么快？
先说结论：  
**多路复用快的原因在于，操作系统提供了这样的系统调用，使得原来的 while 循环里多次系统调用，变成了一次系统调用 + 内核层遍历这些文件描述符。就好比我们平时写业务代码，把原来 while 循环里调 http 接口进行批量，改成了让对方提供一个批量添加的 http 接口，然后我们一次 rpc 请求就完成了批量添加一个道理**

##### 阻塞IO
最开始的时候，网络I/O采用的是阻塞IO，就像下面的伪代码那样：
```java
listenfd = socket();   // 打开一个网络通信端口
bind(listenfd);        // 绑定
listen(listenfd);      // 监听
while(1) {
  connfd = accept(listenfd);  // 阻塞建立连接
  int n = read(connfd, buf);  // 阻塞读数据
  doSomeThing(buf);  // 利用读到的数据做些什么
  close(connfd);     // 关闭连接，循环等待下一个连接
}
```

动图展现出来就是下面这样：  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-02-01.gif)  
<center>阻塞IO示意图</center>  
可以看到，服务端的线程阻塞在了两个地方，<font color=red>一个是`accept` 函数，一个是 `read` 函数</font>。其中read 函数的底层会阻塞在下面两个阶段：  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-02-02.gif)  
<center>read函数实现过程</center>  
总结一下，read函数实现过程大致如下：  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-02-01.jpg)  
<center>read函数实现过程</center>  
问题的根本在于：  
**<font color=red>如果这个连接的客户端一直不发数据，那么服务端线程将会一直阻塞在 read 函数上不返回，也无法接受其他客户端连接</font>**

##### 非阻塞IO
既然问题在于`read`函数上，那么能不能改造一下呢？换做是我，我能够想到的就是每次都创建一个新的进程或线程，去调用`read`函数做业务处理。但是，这不叫非阻塞 IO，只不过用了多线程的手段使得主线程没有卡在 read 函数上不往下走罢了。**但是本质上操作系统为我们提供的`read`函数仍然是阻塞的**

所以真正的非阻塞 IO，不能是通过在用户层玩儿的小把戏，而是要在操作系统动刀子。说来就来，**前辈们为大家在系统层级提供了一个非阻塞的 read 函数**：如果没有数据到达时，立刻返回一个错误值（-1），而不是阻塞等待

此时，用户层面就只需要循环调用 read，直到返回值不为 -1时再开始处理业务即可。这种方法结合上层应用的多线程就能比较好的解决传统阻塞IO的问题了（注意是“比较好”，自然问题还是有的），动图表示如下：  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-02-03.gif)  
<center>非阻塞的 read函数</center>  
其中有个细节：  
非阻塞的 read，指的是在数据到达前，即数据还未到达网卡，或者到达网卡但还没有拷贝到内核缓冲区之前，这个阶段是非阻塞的。**<font color=red>当数据已到达内核缓冲区，此时调用 read 函数仍然是阻塞的，需要等待数据从内核缓冲区拷贝到用户缓冲区，才能返回</font>**

##### IO多路复用-select
上面的非阻塞IO+多线程虽然解决了新连接不被阻塞的问题，但是带来了新的问题：**为每个客户端创建一个线程，服务器端的线程资源很容易被耗光**  
所以，IO多路复用应运而生，最开始IO多路复用的原理如下：  
可以每`accept`一个客户端连接后，将这个文件描述符（`connfd`）放到一个数组里，然后核心的处理线程会一直不断遍历这个数组，调用每一个元素的`非阻塞 read` 方法，这样就**成功用一个线程处理了多个客户端连接**  
这个时候就有个疑问了：每次都要去调用read函数，从上面也知道read函数涉及到了用户态和内核态的切换，那岂不是有很多次多于的切换开销呢？所以依旧想办法在系统层面动刀子：系统提供了一个有这样效果的函数：  
**将一批文件描述符通过一次系统调用传给内核，由内核层去遍历，才能真正解决这个问题**  
这就是`select函数`：通过它，调用者可以在用户层级可以把一个文件描述符的数组发给操作系统，让操作系统去遍历，确定哪个文件描述符可以读写，然后告诉用户去处理：  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-02-04.gif)  
<center>select函数的大致过程</center>  
这里可以看一下此时IO多路复用的大致伪代码，通过三个线程来进行无休止的循环来实现：  
- 线程1的循环：不断接受客户端连接，并把 socket 文件描述符放到一个 list 里

```java
while(1) {
  connfd = accept(listenfd);
  fcntl(connfd, F_SETFL, O_NONBLOCK);
  fdlist.add(connfd);
}
```

- 线程2的循环：不再自己遍历，而是调用 `select`，将这批文件描述符数组`list` 交给操作系统去遍历

```java
//
while(1) {
  // 把一堆文件描述符 list 传给 select 函数
  // 有已就绪的文件描述符就返回，nready 表示有多少个就绪的
  nready = select(list);
  ...
}
```

- 线程3的循环：当 `select` 函数返回后，用户依然需要遍历刚刚提交给操作系统的 list，只不过，操作系统会将准备就绪的文件描述符做上标识，用户层将不会再有无意义的系统调用开销

```java
while(1) {
  nready = select(list);
  // 用户层依然要遍历，只不过少了很多无效的系统调用
  for(fd <-- fdlist) {
    if(fd != -1) {
      // 只读已就绪的文件描述符
      read(fd, buf);
      // 总共只有 nready 个已就绪描述符，不用过多遍历
      if(--nready == 0) break;
    }
  }
}
```

总结了一下select函数的一些细节：  
- select 调用需要传入 fd 数组，需要拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。（可优化为不复制）  
- select 在内核层仍然是通过遍历的方式检查文件描述符的就绪状态，是个同步过程，只不过无系统调用切换上下文的开销。（内核层可优化为异步事件通知）  
- select 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。比如加入10000个连接中，真正在发生IO的就一两个，那么剩下的也要被遍历然后调用read函数，这岂不是浪费了？（可优化为只返回给用户就绪的文件描述符，无需用户做无效的遍历）  

##### IO多路复用-poll
它和 select 的主要区别就是，**去掉了 select 只能监听 1024 个文件描述符的限制**
##### IO多路复用-epoll
epoll主要就是针对select的三个问题进行了改进：  
- 内核中保存一份文件描述符集合，无需用户每次都重新传入，只需告诉内核修改的部分即可  
- 内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步 IO 事件唤醒  
- 内核仅会将有 IO 事件的文件描述符返回给用户，用户也无需遍历整个文件描述符集合  

核心在于这三个函数：`epoll_create`、`epoll_ctl`（向内核添加、修改或删除要监控的文件描述符）、`epoll_wait`（会阻塞，类似发起了 select() 调用，当内核监听到IO事件后会异步唤醒，该函数就会返回对应的文件描述符）：  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-02-05.gif)  
<center>epoll模型的大致过程</center>  

##### 总结
- 一切的开始，都起源于这个 read 函数是操作系统提供的，而且是阻塞的，这是传统阻塞IO  
- 为了破这个局，程序员在上层应用通过多线程来防止主线程卡死  
- 后来操作系统发现这个需求比较大，于是在操作系统层面提供了非阻塞的 read 函数，这样程序员就可以在一个while线程内完成多个文件描述符的读取（没有就直接快速返回-1），这就是 非阻塞 IO  
- 但多个文件描述符的读取就需要遍历，当高并发场景越来越多时，用户态遍历的文件描述符也越来越多，相当于在 while 循环里进行了越来越多的系统调用，后来操作系统又发现这个场景需求量较大，于是又在操作系统层面提供了这样的遍历文件描述符的机制，这就是 IO 多路复用  
- 多路复用有三个函数，最开始是 select，然后又发明了 poll 解决了 select 文件描述符的限制，然后又发明了 epoll 解决 select 的三个不足

引用闪客sun大佬的一段总结：  
>所以，IO 模型的演进，其实就是时代的变化，倒逼着操作系统将更多的功能加到自己的内核而已。如果你建立了这样的思维，很容易发现网上的一些错误。比如好多文章说，多路复用之所以效率高，是因为用一个线程就可以监控多个文件描述符。这显然是知其然而不知其所以然，多路复用产生的效果，完全可以由用户态去遍历文件描述符并调用其非阻塞的 read 函数实现。而多路复用快的原因在于，操作系统提供了这样的系统调用，使得原来的 while 循环里多次系统调用，变成了一次系统调用 + 内核层遍历这些文件描述符。就好比我们平时写业务代码，把原来 while 循环里调 http 接口进行批量，改成了让对方提供一个批量添加的 http 接口，然后我们一次 rpc 请求就完成了批量添加一个道理。

### 分布式锁基础版
使用Redis做分布式锁的思路大概是这样的，首先在redis中设置一个值这个操就代表加锁：  
```shell
// 获取锁
// NX是指如果key不存在就成功，key存在返回false，PX可以指定过期时间
SET anyLock unique_value NX PX 30000
```

然后把这个key删除这操作代表释放锁：  
```lua
// 释放锁：通过执行一段lua脚本
// 释放锁涉及到两条指令，这两条指令不是原子性的
// 需要用到redis的lua脚本支持特性，redis执行lua脚本是原子性的
if redis.call("get",KEYS[1]) == ARGV[1] then
return redis.call("del",KEYS[1])
else
return 0
end
```

- **使用`SET key value NX PX milliseconds` 命令**  
    - 操作可以看成`setnx`和`expire`的结合体，是**原子性**的  
    - 如果不用，先设置了值，再设置过期时间，这个不是原子性操作，有可能在设置过期时间之前宕机，会造成死锁(key永久存在)  
    - 建议设置过期时间时附件随机数，避免大量的key同时过期  
- **保持加锁和解锁的唯一性**  
    - 这个是为了避免锁自动过期后被意外删除：假设A获取了锁，过期时间30s，此时35s之后，锁已经自动释放了，A去释放锁，但是此时可能B获取了锁，A客户端就会把B的锁给删除掉  
    - 解决办法：在解锁的时候，需要验证value是和加锁的一致才删除key  
    有一个稍微安全一点的方案是为 set 指令的 value 参数设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key，这是为了确保当前线程占有的锁不会被其它线程释放，除非这个锁是过期了被服务器自动释放的。 但是匹配 value 和删除 key 不是一个原子操作，Redis 也没有提供类似于delifequals这样的指令，这就需要使用 Lua 脚本来处理了，因为 Lua 脚本可以保证连续多个指令的原子性执行

脚本示例：   
```lua
if redis.call("get",KEYS[1]) == ARGV[1]
then
    return redis.call("del",KEYS[1])
else
    return 0
end
```
先获取 KEYS\[1] 的 value，判断 KEYS\[1] 的 value 是否和 ARGV\[1] 的值相等，如果相等，则删除 KEYS\[1]

使用示例：  
```java
// 脚本解锁
String script = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end";
//KEYS[1] 对应“lock”，ARGV[1] 对应 “uuid”，含义就是如果 lock 的 value 等于 uuid 则删除 lock
redisTemplate.execute(new DefaultRedisScript<Long>(script, Long.class), Arrays.asList("lock"), uuid);
```

### Redisson版本

##### RedLock
要讲RedLock算法，有必要先说一下Redis的3种部署方式  
- **单机模式**  
如果采用单机部署模式，会存在单点问题，只要redis故障了，分布式锁就失效了，所以一般单节点很少用来做分布式锁  
- **Redis Sentinel模式**  
采用master-slave模式，加锁的时候只对一个节点加锁，即便有sentinel，但是如果master节点故障了，发生主从切换过程中请求来获取锁或者释放锁时就会有可能出现锁丢失的问题  
- **Redis Cluster模式**  

为了解决以上的问题，Redis作者提出了一个`RedLock的算法`，这个算法的大概原理：假设redis的部署模式是redis cluster，总共有5个master节点，通过以下步骤获取一把锁：  
1. 获取当前时间戳，单位是毫秒  
2. 轮流用相同的key和随机值在这5个节点上请求锁，在这一步里，客户端在每个master上请求锁时，会有一个和总的锁释放时间相比小的多的超时时间。比如如果锁自动释放时间是10秒钟，那每个节点锁请求的超时时间可能是5-50毫秒的范围，这个可以防止一个客户端在某个宕掉的master节点上阻塞过长时间，如果一个master节点不可用了，应该尽快尝试下一个master节点  
3. 客户端计算第二步中获取锁所花的时间，只有当客户端在大多数master节点（n / 2 +1，所以在这里是3个）上成功获取了锁，而且总共消耗的时间不超过锁释放时间，这个锁就认为是获取成功了  
4. 如果锁获取成功了，那现在锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间  
5. 如果锁获取失败了，不管是因为获取成功的锁不超过一半（N/2+1)还是因为总消耗时间超过了锁释放时间，客户端都会到每个master节点上释放锁

##### 是什么？
针对分布式锁的常用有很多解决方案，Redis只是其中的一个选择，而Java 版的Redis分布式锁的框架就是 Redisson
##### 有什么？

- **Netty**  
没错，就是NIO框架Netty。Redisson采用了基于NIO的Netty框架，不仅能作为Redis底层驱动客户端，具备提供对Redis各种组态形式的连接功能，对Redis命令能以同步发送、异步形式发送、异步流形式发送或管道形式发送的功能，LUA脚本执行处理，以及处理返回结果的功能  
- **基础数据结构**  
将原生的Redis `Hash`，`List`，`Set`，`String`，`Geo`，`HyperLogLog`等数据结构封装为Java里大家最熟悉的映射（`Map`），列表（`List`），集（`Set`），通用对象桶（`Object Bucket`），地理空间对象桶（`Geospatial Bucket`），基数估计算法（`HyperLogLog`）等结构  
- **分布式数据结构**  
提供了分布式的多值映射（Multimap），本地缓存映射（LocalCachedMap），有序集（SortedSet），计分排序集（ScoredSortedSet），字典排序集（LexSortedSet），列队（Queue），阻塞队列（Blocking Queue），有界阻塞列队（Bounded Blocking Queue），双端队列（Deque），阻塞双端列队（Blocking Deque），阻塞公平列队（Blocking Fair Queue），延迟列队（Delayed Queue），布隆过滤器（Bloom Filter），原子整长形（AtomicLong），原子双精度浮点数（AtomicDouble），BitSet等Redis原本没有的分布式数据结构  
- **分布式锁**  
Redisson还实现了Redis文档中提到像分布式锁Lock这样的更高阶应用场景。事实上Redisson并没有不止步于此，在分布式锁的基础上还提供了联锁（MultiLock），读写锁（ReadWriteLock），公平锁（Fair Lock），红锁（RedLock），信号量（Semaphore），可过期性信号量（PermitExpirableSemaphore）和闭锁（CountDownLatch）这些实际当中对多线程高并发应用至关重要的基本部件。正是通过实现基于Redis的高阶应用方案，使Redisson成为构建分布式系统的重要工具  
- **节点**  
Redisson作为独立节点可以用于独立执行其他节点发布到分布式执行服务和分布式调度服务里的远程任务

##### SpringBoot整合Redisson
- 引入 Maven 依赖

```xml
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.15.5</version>
</dependency>
```

- 单节点 Redis配置

```java
@Configuration
public class MyRedissonConfig {
    /**
     * 对 Redisson 的使用都是通过 RedissonClient 对象
     * @return
     * @throws IOException
     */
    @Bean(destroyMethod="shutdown") // 服务停止后调用 shutdown 方法。
    public RedissonClient redisson() throws IOException {
        // 1.创建配置
        Config config = new Config();
        // 集群模式
        // config.useClusterServers().addNodeAddress("127.0.0.1:7004", "127.0.0.1:7001");
        // 2.根据 Config 创建出 RedissonClient 示例。
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");
        return Redisson.create(config);
    }
}
```

- 加锁和解锁  

```java
// 1.获取锁，只要锁的名字一样，获取到的锁就是同一把锁。
RLock lock = redisson.getLock("lockA");

// 2.加锁
lock.lock();
try {
    //do somthing
} catch (Exception e) {
    //TODO
} finally {
    // 3.解锁
    lock.unlock();
}
```

##### 看门狗
如果负责储存这个分布式锁的 Redisson 节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期

原理大致如下:如果未制定 lock 的超时时间，就使用 30 秒作为看门狗的默认时间。只要占锁成功，就会启动一个定时任务：每隔 10 秒重新给锁设置过期的时间，过期时间为 30 秒,**可以理解为只要没解锁就会自动续期**

默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改`Config.lockWatchdogTimeout`来另行指定

注意：**<font color=red>如果整个占用锁的时间超过了提前设置的锁过期时间，此时如果再进行释放锁操作时，会报错</font>**
##### 分布式读写锁
基于 Redis 的 Redisson 分布式可重入读写锁`RReadWriteLock`实现了`java.util.concurrent.locks.ReadWriteLock接口`。其中读锁和写锁都继承了`RLock接口`  

写锁是一个排他锁（互斥锁），读锁是一个共享锁

**读读**：相当于没加锁，可以并发读  
**读写**：写锁需要等待读锁释放锁  
**写写**：互斥，需要等待对方的锁释放  
**写读**：读锁需要等待写锁释放

```java
RReadWriteLock rwlock = redisson.getReadWriteLock("anyRWLock");
// 最常见的使用方法
rwlock.readLock().lock();
// 或
rwlock.writeLock().lock();


// 10秒钟以后自动解锁
// 无需调用unlock方法手动解锁
rwlock.readLock().lock(10, TimeUnit.SECONDS);
// 或
rwlock.writeLock().lock(10, TimeUnit.SECONDS);

// 尝试加锁，最多等待100秒，上锁以后10秒自动解锁
boolean res = rwlock.readLock().tryLock(100, 10, TimeUnit.SECONDS);
// 或
boolean res = rwlock.writeLock().tryLock(100, 10, TimeUnit.SECONDS);
...
lock.unlock();
```

##### 分布式信号量
基于Redis的Redisson的分布式信号量（Semaphore）Java对象RSemaphore采用了与java.util.concurrent.Semaphore相似的接口和用法。同时还提供了异步（Async）、反射式（Reactive）和RxJava2标准的接口

```java
//举例：用 Redis 客户端添加了一个 key：“park”，值等于 3，代表信号量为 park，可以提供三次acquire()
// 占据信号量
RSemaphore park = redisson.getSemaphore("park");
park.acquire();
 
//获取信号量（停车场）
RSemaphore park = redisson.getSemaphore("park");
// 释放一个信号（停车位）
park.release();
```

### Zookeeper的分布式锁
既然都说到了redis的分布式锁，那么就顺带把Zookeeper的分布式锁给总结了吧。常见的分布式锁实现方案里面，除了使用redis来实现之外，使用zookeeper也可以实现分布式锁。
##### 是什么？
Zookeeper是一种提供配置管理、分布式协同以及命名的中心化服务。zk的模型是这样的：zk包含一系列的节点，叫做znode，就好像文件系统一样每个znode表示一个目录，然后znode有一些特性：  
- **有序节点**  
假如当前有一个父节点为`/lock`，同时在这个父节点下面创建了有序的子节点（zookeeper提供了一个可选的有序特性）例如创建子节点`/lock/node-`并且指明有序，那么zookeeper在生成子节点时会根据当前的子节点数量自动添加整数序号。如果是第一个创建的子节点，那么生成的子节点为`/lock/node-0000000000`，下一个节点则为`/lock/node-0000000001`，依次类推  
- **临时节点**  
客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点  
- **事件监听**  
在读取数据时，可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper会通知客户端。当前zookeeper有如下四种事件：**节点创建、节点删除、节点数据修改、子节点变更**

##### 大致原理
- 使用zk的临时节点和有序节点，每个线程获取锁就是在zk创建一个临时有序的节点，比如在/lock/目录下  
- 创建节点成功后，获取/lock目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点：如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功；如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听  
- 举例  
比如当前线程获取到的节点序号为`/lock/003`,然后所有的节点列表为`[/lock/001,/lock/002,/lock/003]`,则对`/lock/002`这个节点添加一个事件监听器。如果锁释放了，会唤醒下一个序号的节点，然后重新执行判断是否自己的节点序号是最小。比如`/lock/001`释放了，`/lock/002`监听到事件，此时节点集合为`[/lock/002,/lock/003]`,则`/lock/002`为最小序号节点，获取到锁  

##### 怎么玩？
Curator是一个zookeeper的开源客户端，也提供了分布式锁的实现：  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-02-02.jpg)  
<center>curator实现分布式锁的底层原理</center>

代码如下：

```java
InterProcessMutex interProcessMutex = new InterProcessMutex(client,"/anyLock");
interProcessMutex.acquire();
interProcessMutex.release();
```

##### 总结
对于redis的分布式锁而言，它有以下缺点：  
- 它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能  
- 另外来说的话，redis的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮，即便使用redlock算法来实现，在某些复杂场景下，也无法保证其实现100%没有问题  
- 但是另一方面使用redis实现分布式锁在很多企业中非常常见，而且大部分情况下都不会遇到所谓的极端复杂场景，所以使用redis作为分布式锁也不失为一种好的方案，最重要的一点是redis的性能很高，可以支撑高并发的获取、释放锁操作  

对于zk分布式锁而言:
- zookeeper天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁  
- 如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小  
- 但是如果有较多的客户端频繁的申请加锁、释放锁，对于zk集群的压力会比较大

怎么选用要看具体的实际场景了，如果公司里面有zk集群条件，优先选用zk实现，但是如果说公司里面只有redis集群，没有条件搭建zk集群。那么其实用redis来实现也可以，另外还可能是系统设计者考虑到了系统已经有redis，但是又不希望再次引入一些外部依赖的情况下，可以选用redis  