---
layout:     post
title:      "可不敢吹自己会Redis-03"
subtitle:   "Scan、主从同步"
date:       2021-04-24
author:     "ThreeJin"
header-mask: 0.5
catalog: true
header-img: "https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-bk.png"
tags:
    - Java
    - Redis
    - Zookeeper

---
> 资料来源于网络上各位前辈（老钱）

### 前言
在平时线上 Redis 维护工作中，有时候需要从 Redis 实例成千上万的 key 中找出特定前缀的 key 列表来手动处理数据，可能是修改它的值，也可能是删除 key。这里就有一个问题，如何从海量的 key 中找出满足特定前缀的 key 列表来？
### Scan
##### keys的缺点
- 没有 `offset`、`limit` 参数，一次性吐出所有满足条件的 `key`，万一实例中有几百 w 个 key 满足条件，那是很可怕的事情  
- `keys` 算法是遍历算法，复杂度是 O(n)，如果实例中有千万级以上的 key，这个指令就会导致 Redis 服务卡顿，所有读写 Redis 的其它的指令都会被延后甚至会超时报错

##### scan的特点
- 复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程  
- 提供 `limit` 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少  
- 同 keys 一样，它也提供模式匹配功能  
- 服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数  
- 返回的结果可能会有重复，需要客户端去重复，这点非常重要  
- 遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的  
- 单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零  

##### 怎么玩儿？
`scan` 参数提供了三个参数，第一个是 `cursor 整数值`，第二个是 `key 的正则模式`，第三个是`遍历的 limit hint`。第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束

```txt
127.0.0.1:6379> scan 0 match key99* count 1000
1) "13976"
2)  1) "key9911"
    2) "key9974"
    3) "key9994"
    4) "key9910"
    5) "key9907"
    6) "key9989"
    7) "key9971"
    8) "key99"
    9) "key9966"
   10) "key992"
   11) "key9903"
   12) "key9905"
127.0.0.1:6379> scan 13976 match key99* count 1000
1) "1996"
2)  1) "key9982"
    2) "key9997"
    3) "key9963"
    4) "key996"
    5) "key9912"
    6) "key9999"
    7) "key9921"
    8) "key994"
    9) "key9956"
   10) "key9919"
```

从上面的过程可以看到虽然提供的 limit 是 1000，但是返回的结果只有 10 个左右。因为这个 limit 不是限定返回结果的数量，而是**限定服务器单次遍历的字典槽位数量(约等于)**。如果将 limit 设置为 10，虽然返回结果是空的，但是游标值不为零，意味着遍历还没结束

##### scan是怎么遍历的？
Redis 中所有的 key 都存储在一个很大的字典中，这个字典的结构和 Java 中的 HashMap 一样，是一维数组 + 二维链表结构，第一维数组的大小总是 2^n(n>=0)，扩容一次数组大小空间加倍，也就是 n++

scan 指令返回的游标就是第一维数组的位置索引，这个位置索引称为槽 (`slot`)。如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。limit 参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每一次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端

scan 的遍历顺序非常特别。它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏
##### 渐进式 rehash
Java 的 HashMap 在扩容时会一次性将旧数组下挂接的元素全部转移到新数组下面。如果 HashMap 中元素特别多，线程就会出现卡顿现象。Redis 为了解决这个问题，它采用渐进式 rehash

它会同时保留旧数组和新数组，然后在定时任务中以及后续对 hash 的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上。这意味着要操作处于 rehash 中的字典，需要同时访问新旧两个数组结构。如果在旧数组下面找不到元素，还需要去新数组下面去寻找

scan 也需要考虑这个问题，对与 rehash 中的字典，它需要同时扫描新旧槽位，然后将结果融合后返回给客户端

##### scn扩展命令
`zscan` 遍历 zset 集合元素，`hscan` 遍历 hash 字典的元素、`sscan` 遍历 set 集合的元素
##### 大 key 扫描
大key的对象在 Redis 的集群数据迁移带来了很大的问题，因为在集群环境下，如果某个 key 太大，会数据导致迁移卡顿。另外在内存分配上，如果一个 key 太大，那么当它需要扩容时，会一次性申请更大的一块内存，这也会导致卡顿。如果这个大 key 被删除，内存会一次性回收，卡顿现象会再一次产生

如果观察到 Redis 的内存大起大落，这极有可能是因为大 key 导致的，这时候需要定位出具体是那个 key，进一步定位出具体的业务来源，然后再改进相关业务代码设计。那如何定位大 key 呢？

为了避免对线上 Redis 带来卡顿，这就要用到 scan 指令，对于扫描出来的每一个 key，使用 type 指令获得 key 的类型，然后使用相应数据结构的 size 或者 len 方法来得到它的大小，对于每一种类型，保留大小的前 N 名作为扫描结果展示出来。

上面这样的过程需要编写脚本，比较繁琐，不过 Redis 官方已经在 redis-cli 指令中提供了这样的扫描功能，可以直接拿来即用

`redis-cli -h 127.0.0.1 -p 7001 –-bigkeys -i 0.1`

上面这个指令每隔 100 条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的时间会变长
### 主从同步
Redis 同步支持主从同步和从从同步，从从同步功能是 Redis 后续版本增加的功能，为了减轻主库的同步负担  
![](https://gitee.com/liaoxinyiqiqi/my-blog-images/raw/master/img/java-redis-03-01.jpg)  
<center>Redis的同步示意图</center>  
Redis 同步的是指令流，主节点会将那些对自己的状态产生修改性影响的指令记录在本地的内存 `buffer` 中，然后异步将 buffer 中的指令同步到从节点，从节点一边执行同步的指令流来达到和主节点一样的状态，一边向主节点反馈自己同步到哪里了 (偏移量)
##### 同步机制-增量同步
因为内存的 buffer 是有限的，所以 Redis 主库不能将所有的指令都记录在内存 buffer 中。Redis 的复制内存 buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容  
如果因为网络状况不好，从节点在短时间内无法和主节点进行同步，那么当网络状况恢复时，Redis 的主节点中那些没有同步的指令在 buffer 中有可能已经被后续的指令覆盖掉了，从节点将无法直接通过指令流来进行同步
##### 同步机制-快照同步
快照同步是一个非常耗费资源的操作，它首先需要在主库上进行一次 bgsave 将当前内存的数据全部快照到磁盘文件中，然后再将快照文件的内容全部传送到从节点。从节点将快照文件接受完毕后，立即执行一次全量加载，加载之前先要将当前内存的数据清空。加载完毕后通知主节点继续进行增量同步

在整个快照同步进行的过程中，主节点的复制 buffer 还在不停的往前移动，如果快照同步的时间过长或者复制 buffer 太小，都会导致同步期间的增量指令在复制 buffer 中被覆盖，这样就会导致快照同步完成后无法进行增量复制，然后会再次发起快照同步，如此极有可能会陷入快照同步的死循环

**所以务必配置一个合适的复制 buffer 大小参数，避免快照复制的死循环**
##### 从节点增加
当从节点刚刚加入到集群时，它必须先要进行一次快照同步，同步完成后再继续进行增量同步
##### 无盘复制
主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。

所以从 Redis 2.8.18 版开始支持无盘复制。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一边将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载
##### Wait 指令
**Redis 的复制是异步进行的**，`wait` 指令可以让异步复制变身同步复制。wait 指令是 Redis3.0 版本以后才出现的

wait 提供两个参数，第一个参数是从库的数量 `N`，第二个参数是时间 `t`，以`毫秒`为单位。它表示等待 wait 指令之前的所有写操作同步到 N 个从库 (也就是确保 N 个从库的同步没有滞后)，最多等待时间 t。**如果时间 t=0，表示无限等待直到 N 个从库同步完成达成一致**

假设此时出现了网络分区，wait 指令第二个参数时间 t=0，主从同步无法继续进行，wait 指令会永远阻塞，Redis 服务器将丧失可用性